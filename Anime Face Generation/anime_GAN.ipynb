{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-16T21:55:15.24467Z","iopub.execute_input":"2022-04-16T21:55:15.244945Z","iopub.status.idle":"2022-04-16T21:55:15.267812Z","shell.execute_reply.started":"2022-04-16T21:55:15.244868Z","shell.execute_reply":"2022-04-16T21:55:15.267099Z"},"id":"3pL6QPLimZws","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Download Dataset**","metadata":{"id":"jxpOsFofmZww"}},{"cell_type":"code","source":"# get dataset from huggingface hub\n!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n!apt-get install git-lfs\n!git lfs install\n!git clone https://huggingface.co/datasets/LeoFeng/MLHW_6\n!unzip ./MLHW_6/faces.zip -d .","metadata":{"execution":{"iopub.status.busy":"2022-04-16T21:55:15.26925Z","iopub.execute_input":"2022-04-16T21:55:15.269533Z"},"id":"kDmFHyfamZwy","outputId":"2956c509-5ef1-4948-e7a4-59a66b2e7b4b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **StyleGan2**","metadata":{"id":"U6YUAC8fmZwz"}},{"cell_type":"code","source":"# Installation\n!pip install stylegan2_pytorch","metadata":{"id":"6PMi8UyumZw0","outputId":"0d90f992-c7d0-4b08-82f5-5bf04d226dce","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!stylegan2_pytorch --data ./faces --models_dir ./models --num-train-steps 35000 --num-image-tiles 1 --batch-size 6 --gradient-accumulate-every 2 --network-capacity 12\n#!stylegan2_pytorch --data ./faces --name stylegan2 --models_dir ./models --num-train-steps 100 --image-size 64 --save-every 10 --evaluate-every 10","metadata":{"id":"LsEUGOBdmZw0","outputId":"d317d261-a897-4c4f-f5dc-a986e3e04396","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Inference**\n**In this section, we will use trainer to train model**","metadata":{"id":"fQloN8G0mZw1"}},{"cell_type":"code","source":"!stylegan2_pytorch  --generate --num_generate 1000 --image-size 64 --results_dir ./output_results --num-image-tiles 1","metadata":{"id":"0naJBdW_mZw2","outputId":"c93b412d-cac6-4c29-e69a-0e8c73ba8386","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename\nfrom PIL import Image\nimport os\npath = './output_results/default'\nfiles = os.listdir(path)\n\nfor index, file in enumerate(files):\n    img = Image.open(os.path.join(path, file))\n    img = img.resize((64,64), Image.ANTIALIAS)\n    img.save(os.path.join(path, file), optimize=True)\n\nfor index, file in enumerate(files):\n    if file.split(\"-\")[-1][0] == 'm' or file.split(\"-\")[-1][0] == 'e':\n        os.remove(os.path.join(path, file))\n    else:\n        os.rename(os.path.join(path, file), os.path.join(path, file.split(\"-\")[-1]))\n        \nos.rename(os.path.join(path, \"0.jpg\"), os.path.join(path, \"1000.jpg\"))\n\n# for index, file in enumerate(files):\n#    os.rename(os.path.join(path, file), os.path.join(path, ''.join([str(index+1), '.jpg'])))","metadata":{"id":"O7cMyit7mZw2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Prepare .tar file for submission**","metadata":{"id":"Bg9YWoVcmZw3"}},{"cell_type":"code","source":"%cd output_results/default\n!tar -zcf ../submission.tgz *.jpg","metadata":{"id":"IwEy7N6amZw4","outputId":"7c02f73b-c882-49c2-b586-38f694d0100e","trusted":true},"execution_count":null,"outputs":[]}]}