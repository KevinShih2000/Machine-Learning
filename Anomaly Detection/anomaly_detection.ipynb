{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 8 - Anomaly Detection**\n\nIf there are any questions, please contact mlta-2022spring-ta@googlegroups.com\n\nSlide:    [Link]()ã€€Kaggle: [Link](https://www.kaggle.com/c/ml2022spring-hw8)","metadata":{"id":"YiVfKn-6tXz8"}},{"cell_type":"markdown","source":"# Set up the environment\n","metadata":{"id":"bDk9r2YOcDc9"}},{"cell_type":"markdown","source":"## Package installation","metadata":{"id":"Oi12tJMYWi0Q"}},{"cell_type":"code","source":"# Training progress bar\n!pip install -q qqdm","metadata":{"id":"7LexxyPWWjJB","outputId":"3a733a84-fca3-4e7c-fb9b-bfd5f890114d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading data","metadata":{"id":"DCgNXSsEWuY7"}},{"cell_type":"code","source":"!wget https://github.com/MachineLearningHW/HW8_Dataset/releases/download/v1.0.0/data.zip","metadata":{"id":"SCLJtgF2BLSK","outputId":"54d462c4-2121-46a9-a966-1ca9b01e7b61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip data.zip","metadata":{"id":"0K5kmlkuWzhJ","outputId":"c12176a4-f513-4ed3-c351-c82ef26e8072"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import packages","metadata":{"id":"HNe7QU7n7cqh"}},{"cell_type":"code","source":"import random\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision.models as models\nfrom torch.optim import Adam, AdamW\nfrom qqdm import qqdm, format_str\nimport pandas as pd","metadata":{"id":"Jk3qFK_a7k8P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading data","metadata":{"id":"6X6fkGPnYyaF"}},{"cell_type":"code","source":"\ntrain = np.load('data/trainingset.npy', allow_pickle=True)\ntest = np.load('data/testingset.npy', allow_pickle=True)\n\nprint(train.shape)\nprint(test.shape)","metadata":{"id":"k7Wd4yiUYzAm","outputId":"2c2fa7bf-1c0a-4090-ac16-627c1fe5ca5c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random seed\nSet the random seed to a certain value for reproducibility.","metadata":{"id":"_flpmj6OYIa6"}},{"cell_type":"code","source":"def same_seeds(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nsame_seeds(48763)","metadata":{"id":"Gb-dgXQYYI2Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Autoencoder","metadata":{"id":"zR9zC0_Df-CR"}},{"cell_type":"markdown","source":"# Models & loss","metadata":{"id":"1EbfwRREhA7c"}},{"cell_type":"code","source":"class fcn_autoencoder(nn.Module):\n    def __init__(self):\n        super(fcn_autoencoder, self).__init__()\n        self.encoder1 = nn.Sequential(\n            nn.Linear(64 * 64 * 3, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(), \n            nn.Linear(128, 64), \n            nn.ReLU(), \n            nn.Linear(64, 32)\n        )\n        \n        self.encoder2 = nn.Sequential(\n            nn.Linear(64 * 64 * 3, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(), \n            nn.Linear(64, 32), \n            nn.ReLU(), \n            nn.Linear(32, 16)\n        )\n        \n        self.encoder3 = nn.Sequential(\n            nn.Linear(64 * 64 * 3, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(), \n            nn.Linear(128, 64), \n            nn.ReLU(), \n            nn.Linear(64, 16)\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(64, 128),\n            nn.ReLU(), \n            nn.Linear(128, 256),\n            nn.ReLU(),\n            nn.Linear(256, 512),\n            nn.ReLU(), \n            nn.Linear(512, 64 * 64 * 3), \n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        y1 = self.encoder1(x)\n        y2 = self.encoder2(x)\n        y3 = self.encoder3(x)\n        x = torch.cat((y1, y2, y3), 1)\n        x = self.decoder(x)\n        return x\n\n\nclass conv_autoencoder(nn.Module):\n    def __init__(self):\n        super(conv_autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 16, 4, stride=2, padding=1),         \n            nn.ReLU(),\n            nn.Conv2d(16, 32, 4, stride=2, padding=1),        \n            nn.ReLU(),\n            nn.Conv2d(32, 64, 4, stride=2, padding=1),         \n            nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(32, 16, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(16, 3, 4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\n\nclass VAE(nn.Module):\n    def __init__(self):\n        super(VAE, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 12, 4, stride=2, padding=1),            \n            nn.ReLU(),\n            nn.Conv2d(12, 24, 4, stride=2, padding=1),    \n            nn.ReLU(),\n        )\n        self.enc_out_1 = nn.Sequential(\n            nn.Conv2d(24, 48, 4, stride=2, padding=1),  \n            nn.ReLU(),\n        )\n        self.enc_out_2 = nn.Sequential(\n            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n            nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1), \n            nn.Tanh(),\n        )\n\n    def encode(self, x):\n        h1 = self.encoder(x)\n        return self.enc_out_1(h1), self.enc_out_2(h1)\n\n    def reparametrize(self, mu, logvar):\n        std = logvar.mul(0.5).exp_()\n        if torch.cuda.is_available():\n            eps = torch.cuda.FloatTensor(std.size()).normal_()\n        else:\n            eps = torch.FloatTensor(std.size()).normal_()\n        eps = Variable(eps)\n        return eps.mul(std).add_(mu)\n\n    def decode(self, z):\n        return self.decoder(z)\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparametrize(mu, logvar)\n        return self.decode(z), mu, logvar\n\n\ndef loss_vae(recon_x, x, mu, logvar, criterion):\n    \"\"\"\n    recon_x: generating images\n    x: origin images\n    mu: latent mean\n    logvar: latent log variance\n    \"\"\"\n    mse = criterion(recon_x, x)\n    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n    KLD = torch.sum(KLD_element).mul_(-0.5)\n    return mse + KLD","metadata":{"id":"Wi8ds1fugCkR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset module\n\nModule for obtaining and processing data. The transform function here normalizes image's pixels from [0, 255] to [-1.0, 1.0].\n","metadata":{"id":"vrJ9bScg9AgO"}},{"cell_type":"code","source":"class CustomTensorDataset(TensorDataset):\n    \"\"\"TensorDataset with support of transforms.\n    \"\"\"\n    def __init__(self, tensors):\n        self.tensors = tensors\n        if tensors.shape[-1] == 3:\n            self.tensors = tensors.permute(0, 3, 1, 2)\n        \n        self.transform = transforms.Compose([\n          transforms.Lambda(lambda x: x.to(torch.float32)),\n          transforms.Lambda(lambda x: 2. * x/255. - 1.),\n        ])\n        \n    def __getitem__(self, index):\n        x = self.tensors[index]\n        \n        if self.transform:\n            # mapping images to [-1.0, 1.0]\n            x = self.transform(x)\n\n        return x\n\n    def __len__(self):\n        return len(self.tensors)","metadata":{"id":"33fWhE-h9LPq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"XKNUImqUhIeq"}},{"cell_type":"markdown","source":"## Configuration\n","metadata":{"id":"7ebAJdjFmS08"}},{"cell_type":"code","source":"# Training hyperparameters\nnum_epochs = 300\nbatch_size = 2000\nlearning_rate = 1e-3\n\n# Build training dataloader\nx = torch.from_numpy(train)\ntrain_dataset = CustomTensorDataset(x)\n\ntrain_sampler = RandomSampler(train_dataset)\ntrain_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n\n# Model\nmodel_type = 'fcn'   # selecting a model type from {'cnn', 'fcn', 'vae', 'resnet'}\nmodel_classes = {'fcn': fcn_autoencoder(), 'cnn': conv_autoencoder(), 'vae': VAE()}\nmodel = model_classes[model_type].cuda()\n\n# Loss and optimizer\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"id":"in7yLfmqtZTk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training loop","metadata":{"id":"wyooN-JPm8sS"}},{"cell_type":"code","source":"\nbest_loss = np.inf\nmodel.train()\n\nqqdm_train = qqdm(range(num_epochs), desc=format_str('bold', 'Description'))\nfor epoch in qqdm_train:\n    tot_loss = list()\n    for data in train_dataloader:\n\n        # ===================loading=====================\n        img = data.float().cuda()\n        if model_type in ['fcn']:\n            img = img.view(img.shape[0], -1)\n\n        # ===================forward=====================\n        output = model(img)\n        if model_type in ['vae']:\n            loss = loss_vae(output[0], img, output[1], output[2], criterion)\n        else:\n            loss = criterion(output, img)\n\n        tot_loss.append(loss.item())\n        # ===================backward====================\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # ===================save_best====================\n    mean_loss = np.mean(tot_loss)\n    if mean_loss < best_loss:\n        best_loss = mean_loss\n        torch.save(model, 'best_model_{}.pt'.format(model_type))\n    # ===================log========================\n    qqdm_train.set_infos({\n        'epoch': f'{epoch + 1:.0f}/{num_epochs:.0f}',\n        'loss': f'{mean_loss:.4f}',\n    })\n    # ===================save_last========================\n    torch.save(model, 'last_model_{}.pt'.format(model_type))","metadata":{"id":"JoW1UrrxgI_U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\nModel is loaded and generates its anomaly score predictions.","metadata":{"id":"Wk0UxFuchLzR"}},{"cell_type":"markdown","source":"## Initialize\n- dataloader\n- model\n- prediction file","metadata":{"id":"evgMW3OwoGqD"}},{"cell_type":"code","source":"eval_batch_size = 200\n\n# build testing dataloader\ndata = torch.tensor(test, dtype=torch.float32)\ntest_dataset = CustomTensorDataset(data)\ntest_sampler = SequentialSampler(test_dataset)\ntest_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=eval_batch_size, num_workers=1)\neval_loss = nn.MSELoss(reduction='none')\n\n# load trained model\ncheckpoint_path = f'last_model_{model_type}.pt'\nmodel = torch.load(checkpoint_path)\nmodel.eval()\n\n# prediction file \nout_file = 'prediction.csv'","metadata":{"id":"_MBnXAswoKmq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anomality = list()\nwith torch.no_grad():\n    for i, data in enumerate(test_dataloader):\n        img = data.float().cuda()\n        if model_type in ['fcn']:\n            img = img.view(img.shape[0], -1)\n        output = model(img)\n        if model_type in ['vae']:\n            output = output[0]\n        if model_type in ['fcn']:\n            loss = eval_loss(output, img).sum(-1)\n        else:\n            loss = eval_loss(output, img).sum([1, 2, 3])\n        anomality.append(loss)\nanomality = torch.cat(anomality, axis=0)\nanomality = torch.sqrt(anomality).reshape(len(test), 1).cpu().numpy()\n\ndf = pd.DataFrame(anomality, columns=['score'])\ndf.to_csv(out_file, index_label = 'ID')","metadata":{"id":"_1IxCX2iCW6V"},"execution_count":null,"outputs":[]}]}